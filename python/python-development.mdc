
# Python Development Guidelines

**Rationale:** These guidelines promote maintainable, well-tested Python code
using modern tooling and best practices. They emphasize the use of `uv` for
dependency management and establish clear patterns for code quality.

## Running Python Commands

**Guideline:** Use `uv run` for all Python command execution to ensure
consistent environment management and dependency resolution.

### Command Usage Examples

**Preferred patterns:**

```bash
# Run tests
uv run pytest tests/

# Format code
uv run ruff format src/

# Run your application
uv run python -m myapp
```

**Avoid:**

```bash
# These bypass uv's environment management
python -m pytest
python -m ruff format
python myapp.py
```

**Reasoning:** `uv run` ensures commands use the project's exact dependencies
and Python version, preventing "works on my machine" issues.

## Code Quality and Formatting

**Guideline:** Use Ruff for both linting and formatting to maintain consistent
code style across the project.

### Code Quality Examples

**Linting and formatting workflow:**

```bash
# Check for issues
uv run ruff check src/ tests/

# Auto-fix issues where possible
uv run ruff check --fix src/ tests/

# Format code
uv run ruff format src/ tests/
```

**Type hints and documentation example:**

```python
def calculate_user_score(
    user_activities: list[dict[str, Any]],
    weight_factor: float = 1.0
) -> tuple[float, int]:
    """Calculate user engagement score based on activities.

    Args:
        user_activities: List of activity dictionaries with 'points' and
                        'timestamp' keys
        weight_factor: Multiplier for final score calculation

    Returns:
        Tuple of (weighted_score, activity_count)

    Raises:
        ValueError: If weight_factor is negative or activities contain
                   invalid data

    Note:
        Activities older than 30 days receive 50% weight reduction.
    """
```

## Project Structure and Testing

**Guideline:** Organize tests to mirror your source code structure and use
pytest with uv for consistent test execution.

### Project Structure Examples

**Directory structure:**

```text
myproject/
├── src/
│   └── myproject/
│       ├── __init__.py
│       ├── auth/
│       │   ├── __init__.py
│       │   └── handlers.py
│       └── utils/
│           └── helpers.py
└── tests/
    ├── conftest.py
    ├── auth/
    │   └── test_handlers.py
    └── utils/
        └── test_helpers.py
```

**Running tests:**

```bash
# Run all tests
uv run pytest

# Run specific test file
uv run pytest tests/auth/test_handlers.py

# Run with coverage
uv run pytest --cov=src/myproject tests/
```

## Dependency Management

**Guideline:** Use uv's dependency groups to organize different types of
dependencies and keep the main package lightweight.

### Dependency Management Examples

**Adding dependencies:**

```bash
# Main project dependencies
uv add requests pydantic

# Development dependencies
uv add --group dev pytest ruff mypy

# Documentation dependencies
uv add --group docs sphinx mkdocs

# Optional feature dependencies
uv add --group database sqlalchemy psycopg2-binary
```

**Import organization:**

```python
# Standard library imports
import json
import logging
from pathlib import Path

# Third-party imports
import requests
from pydantic import BaseModel

# Local imports
from myproject.auth import authenticate_user
from myproject.utils.helpers import format_response
```

## Error Handling and Debugging

**Guideline:** Use specific exception handling and structured logging instead
of generic approaches.

### Error Handling Examples

**Good error handling:**

```python
import logging

logger = logging.getLogger(__name__)

def process_user_data(user_id: str) -> dict[str, Any]:
    try:
        user_data = fetch_user_from_api(user_id)
    except requests.HTTPError as e:
        if e.response.status_code == 404:
            logger.warning(f"User {user_id} not found in API")
            raise UserNotFoundError(f"User {user_id} does not exist") from e
        else:
            logger.error(f"API error for user {user_id}: {e}")
            raise APIConnectionError("Failed to fetch user data") from e
    except requests.RequestException as e:
        logger.error(f"Network error fetching user {user_id}: {e}")
        raise APIConnectionError("Network error occurred") from e
```

**Avoid:**

```python
def process_user_data(user_id: str) -> dict[str, Any]:
    try:
        user_data = fetch_user_from_api(user_id)
    except Exception as e:
        print(f"Something went wrong: {e}")
        return {}
```

## Performance and Best Practices

**Guideline:** Write clear, readable code first, then optimize based on actual
performance measurements.

### Performance Examples

**Effective patterns:**

```python
# List comprehension for readability
active_users = [
    user for user in users
    if user.last_login > cutoff_date and user.is_verified
]

# Context manager for resource handling
def process_large_file(file_path: Path) -> None:
    with open(file_path, 'r') as file:
        for line_num, line in enumerate(file, 1):
            if line_num % 10000 == 0:
                logger.info(f"Processed {line_num} lines")
            process_line(line)

# Generator for memory efficiency with large datasets
def read_user_batches(batch_size: int = 100) -> Iterator[list[User]]:
    offset = 0
    while True:
        batch = User.objects.offset(offset).limit(batch_size).all()
        if not batch:
            break
        yield batch
        offset += batch_size
```

## AI Assistant Collaboration

**Guideline:** When working with an AI assistant on Python code, provide
context about the project's goals, constraints, and existing patterns.

### AI Collaboration Examples

**Effective collaboration patterns:**

- "This function needs to handle user authentication for our FastAPI app.
  We're using JWT tokens and need to validate against our User model."
- "I'm seeing performance issues with this database query. Can you suggest
  optimizations while maintaining the existing API interface?"
- "This code works but could be more Pythonic. Can you refactor while ensuring
  the existing tests still pass?"

**Include relevant context:**

- Current Python version and key dependencies
- Performance requirements or constraints
- Security considerations
- Existing code patterns in the project
